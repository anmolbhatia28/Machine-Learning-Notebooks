{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Exercise 1 - Linear Regression\n",
    "\n",
    "- [warmUpExercise](#warmUpExercise)\n",
    "- [Linear regression with one variable](#Linear-regression-with-one-variable)\n",
    "- [Gradient Descent](#Gradient-Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### warmUpExercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def warmUpExercise():\n",
    "    return(np.identity(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warmUpExercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression with one variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.       6.1101]\n",
      " [  1.       5.5277]\n",
      " [  1.       8.5186]\n",
      " [  1.       7.0032]\n",
      " [  1.       5.8598]\n",
      " [  1.       8.3829]\n",
      " [  1.       7.4764]\n",
      " [  1.       8.5781]\n",
      " [  1.       6.4862]\n",
      " [  1.       5.0546]\n",
      " [  1.       5.7107]\n",
      " [  1.      14.164 ]\n",
      " [  1.       5.734 ]\n",
      " [  1.       8.4084]\n",
      " [  1.       5.6407]\n",
      " [  1.       5.3794]\n",
      " [  1.       6.3654]\n",
      " [  1.       5.1301]\n",
      " [  1.       6.4296]\n",
      " [  1.       7.0708]\n",
      " [  1.       6.1891]\n",
      " [  1.      20.27  ]\n",
      " [  1.       5.4901]\n",
      " [  1.       6.3261]\n",
      " [  1.       5.5649]\n",
      " [  1.      18.945 ]\n",
      " [  1.      12.828 ]\n",
      " [  1.      10.957 ]\n",
      " [  1.      13.176 ]\n",
      " [  1.      22.203 ]\n",
      " [  1.       5.2524]\n",
      " [  1.       6.5894]\n",
      " [  1.       9.2482]\n",
      " [  1.       5.8918]\n",
      " [  1.       8.2111]\n",
      " [  1.       7.9334]\n",
      " [  1.       8.0959]\n",
      " [  1.       5.6063]\n",
      " [  1.      12.836 ]\n",
      " [  1.       6.3534]\n",
      " [  1.       5.4069]\n",
      " [  1.       6.8825]\n",
      " [  1.      11.708 ]\n",
      " [  1.       5.7737]\n",
      " [  1.       7.8247]\n",
      " [  1.       7.0931]\n",
      " [  1.       5.0702]\n",
      " [  1.       5.8014]\n",
      " [  1.      11.7   ]\n",
      " [  1.       5.5416]\n",
      " [  1.       7.5402]\n",
      " [  1.       5.3077]\n",
      " [  1.       7.4239]\n",
      " [  1.       7.6031]\n",
      " [  1.       6.3328]\n",
      " [  1.       6.3589]\n",
      " [  1.       6.2742]\n",
      " [  1.       5.6397]\n",
      " [  1.       9.3102]\n",
      " [  1.       9.4536]\n",
      " [  1.       8.8254]\n",
      " [  1.       5.1793]\n",
      " [  1.      21.279 ]\n",
      " [  1.      14.908 ]\n",
      " [  1.      18.959 ]\n",
      " [  1.       7.2182]\n",
      " [  1.       8.2951]\n",
      " [  1.      10.236 ]\n",
      " [  1.       5.4994]\n",
      " [  1.      20.341 ]\n",
      " [  1.      10.136 ]\n",
      " [  1.       7.3345]\n",
      " [  1.       6.0062]\n",
      " [  1.       7.2259]\n",
      " [  1.       5.0269]\n",
      " [  1.       6.5479]\n",
      " [  1.       7.5386]\n",
      " [  1.       5.0365]\n",
      " [  1.      10.274 ]\n",
      " [  1.       5.1077]\n",
      " [  1.       5.7292]\n",
      " [  1.       5.1884]\n",
      " [  1.       6.3557]\n",
      " [  1.       9.7687]\n",
      " [  1.       6.5159]\n",
      " [  1.       8.5172]\n",
      " [  1.       9.1802]\n",
      " [  1.       6.002 ]\n",
      " [  1.       5.5204]\n",
      " [  1.       5.0594]\n",
      " [  1.       5.7077]\n",
      " [  1.       7.6366]\n",
      " [  1.       5.8707]\n",
      " [  1.       5.3054]\n",
      " [  1.       8.2934]\n",
      " [  1.      13.394 ]\n",
      " [  1.       5.4369]]\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('data/ex1data1.txt', delimiter=',')\n",
    "X = np.c_[np.ones((data.shape[0],1)),data[:,0]]\n",
    "y = np.c_[data[:,1]]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:,1], y, s=30, c='r', marker='x', linewidths=1)\n",
    "plt.xlabel('Population of City in 10,000s')\n",
    "plt.ylabel('Profit in $10,000s');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta=[[0],[0]]):\n",
    "    m = y.size\n",
    "    J = 0\n",
    "    \n",
    "    h = X.dot(theta)\n",
    "    \n",
    "    J = 1/(2*m)*np.sum(np.square(h-y))\n",
    "    \n",
    "    return(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.072733877455676"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeCost(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, theta=[[0],[0]], alpha=0.01, num_iters=1500):\n",
    "    m = y.size\n",
    "    J_history = np.zeros(num_iters)\n",
    "    \n",
    "    for iter in np.arange(num_iters):\n",
    "        h = X.dot(theta)\n",
    "        theta = theta - alpha*(1/m)*(X.T.dot(h-y))\n",
    "        #X is of size 97*2, so X.T is of size 2*97 and (h - y) is of size 97*1, after dot product we get 2*1, so we subtract from answer \n",
    "        J_history[iter] = computeCost(X, y, theta)\n",
    "    return(theta, J_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta:  [[-3.63029144]\n",
      " [ 1.16636235]]\n"
     ]
    }
   ],
   "source": [
    "# theta for minimized cost J\n",
    "theta , Cost_J = gradientDescent(X, y)\n",
    "print('theta: ',theta)\n",
    "plt.plot(Cost_J)\n",
    "plt.ylabel('Cost J')\n",
    "plt.xlabel('Iterations');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.1101]\n",
      " [  5.5277]\n",
      " [  8.5186]\n",
      " [  7.0032]\n",
      " [  5.8598]\n",
      " [  8.3829]\n",
      " [  7.4764]\n",
      " [  8.5781]\n",
      " [  6.4862]\n",
      " [  5.0546]\n",
      " [  5.7107]\n",
      " [ 14.164 ]\n",
      " [  5.734 ]\n",
      " [  8.4084]\n",
      " [  5.6407]\n",
      " [  5.3794]\n",
      " [  6.3654]\n",
      " [  5.1301]\n",
      " [  6.4296]\n",
      " [  7.0708]\n",
      " [  6.1891]\n",
      " [ 20.27  ]\n",
      " [  5.4901]\n",
      " [  6.3261]\n",
      " [  5.5649]\n",
      " [ 18.945 ]\n",
      " [ 12.828 ]\n",
      " [ 10.957 ]\n",
      " [ 13.176 ]\n",
      " [ 22.203 ]\n",
      " [  5.2524]\n",
      " [  6.5894]\n",
      " [  9.2482]\n",
      " [  5.8918]\n",
      " [  8.2111]\n",
      " [  7.9334]\n",
      " [  8.0959]\n",
      " [  5.6063]\n",
      " [ 12.836 ]\n",
      " [  6.3534]\n",
      " [  5.4069]\n",
      " [  6.8825]\n",
      " [ 11.708 ]\n",
      " [  5.7737]\n",
      " [  7.8247]\n",
      " [  7.0931]\n",
      " [  5.0702]\n",
      " [  5.8014]\n",
      " [ 11.7   ]\n",
      " [  5.5416]\n",
      " [  7.5402]\n",
      " [  5.3077]\n",
      " [  7.4239]\n",
      " [  7.6031]\n",
      " [  6.3328]\n",
      " [  6.3589]\n",
      " [  6.2742]\n",
      " [  5.6397]\n",
      " [  9.3102]\n",
      " [  9.4536]\n",
      " [  8.8254]\n",
      " [  5.1793]\n",
      " [ 21.279 ]\n",
      " [ 14.908 ]\n",
      " [ 18.959 ]\n",
      " [  7.2182]\n",
      " [  8.2951]\n",
      " [ 10.236 ]\n",
      " [  5.4994]\n",
      " [ 20.341 ]\n",
      " [ 10.136 ]\n",
      " [  7.3345]\n",
      " [  6.0062]\n",
      " [  7.2259]\n",
      " [  5.0269]\n",
      " [  6.5479]\n",
      " [  7.5386]\n",
      " [  5.0365]\n",
      " [ 10.274 ]\n",
      " [  5.1077]\n",
      " [  5.7292]\n",
      " [  5.1884]\n",
      " [  6.3557]\n",
      " [  9.7687]\n",
      " [  6.5159]\n",
      " [  8.5172]\n",
      " [  9.1802]\n",
      " [  6.002 ]\n",
      " [  5.5204]\n",
      " [  5.0594]\n",
      " [  5.7077]\n",
      " [  7.6366]\n",
      " [  5.8707]\n",
      " [  5.3054]\n",
      " [  8.2934]\n",
      " [ 13.394 ]\n",
      " [  5.4369]]\n"
     ]
    }
   ],
   "source": [
    "xx = np.arange(5,23)\n",
    "yy = theta[0]+theta[1]*xx\n",
    "\n",
    "# Plot gradient descent\n",
    "plt.scatter(X[:,1], y, s=30, c='r', marker='x', linewidths=1)\n",
    "plt.plot(xx,yy, label='Linear regression (Gradient descent)')\n",
    "\n",
    "# Compare with Scikit-learn Linear regression \n",
    "regr = LinearRegression()\n",
    "# -1 below is for 1-D array and 1 is to put each value in []  \n",
    "regr.fit(X[:,1].reshape(-1,1), y.ravel())\n",
    "# or regr.fit(X[:,1].reshape(X[:-1].reshape(X.shape[0],1),1), y.ravel()) can also be used\n",
    "plt.plot(xx, regr.intercept_+regr.coef_*xx, label='Linear regression (Scikit-learn GLM)')\n",
    "\n",
    "plt.xlim(4,24)\n",
    "plt.xlabel('Population of City in 10,000s')\n",
    "plt.ylabel('Profit in $10,000s')\n",
    "plt.legend(loc=4);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4519.7678677]\n",
      "[ 45342.45012945]\n"
     ]
    }
   ],
   "source": [
    "# Predict profit for a city with population of 35000 and 70000\n",
    "print(theta.T.dot([1, 3.5])*10000)\n",
    "print(theta.T.dot([1, 7])*10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
